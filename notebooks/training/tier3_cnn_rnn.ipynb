{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4020b1c1",
   "metadata": {},
   "source": [
    "# üß¨ Tier 3: CNN + RNN Model Training\n",
    "\n",
    "This notebook implements the **Tier 3 CNN+RNN** architecture - the most expressive model.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        TIER 3: CNN + RNN                                ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                         ‚îÇ\n",
    "‚îÇ   PLM Embeddings (L, D_plm)                                             ‚îÇ\n",
    "‚îÇ          ‚îÇ                                                              ‚îÇ\n",
    "‚îÇ          ‚ñº                                                              ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n",
    "‚îÇ   ‚îÇ      CNN BLOCK (MultiscaleCNN or DeepCNN)       ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îÇk=3‚îÇk=5‚îÇk=7‚îÇ    OR     ‚îÇ Stacked CNN ‚îÇ       ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚î¥‚îÄ‚î¨‚îÄ‚îò           ‚îÇ d=1,2,4,8   ‚îÇ       ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îò             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n",
    "‚îÇ             ‚ñº                         ‚ñº                                 ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n",
    "‚îÇ   ‚îÇ          RNN BLOCK (LSTM / GRU / RNN)           ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îÇ  ‚Üí Layer1 ‚Üí Layer2 ‚Üí                    ‚îÇ   ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îÇ  ‚Üê Layer1 ‚Üê Layer2 ‚Üê  (bidirectional)   ‚îÇ   ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îÇ   Output: hidden √ó 2 (bidirectional)            ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n",
    "‚îÇ                        ‚îÇ                                                ‚îÇ\n",
    "‚îÇ                        ‚ñº                                                ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ\n",
    "‚îÇ   ‚îÇ  MTL Head (q3discarding OR q3guided)            ‚îÇ                   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ\n",
    "‚îÇ                                                                         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## RNN Types\n",
    "\n",
    "| Type | Description | Parameters | Speed |\n",
    "|------|-------------|------------|-------|\n",
    "| **LSTM** | Long Short-Term Memory | Most | Slowest |\n",
    "| **GRU** | Gated Recurrent Unit | 75% of LSTM | Faster |\n",
    "| **RNN** | Vanilla RNN (tanh) | Fewest | Fastest |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500176b",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04421de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üñ•Ô∏è  Device: {DEVICE}\")\n",
    "if DEVICE == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f82b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    Tier3Config, LEAKAGE_TRAIN_IDS,\n",
    "    get_embedding_dim, PLM_EMBEDDING_DIMS,\n",
    ")\n",
    "from src.data import HDF5EmbeddingDataset, collate_fn\n",
    "from src.models import Tier3CNNRNN\n",
    "from src.losses import get_multitask_loss\n",
    "from src.training import Trainer, create_optimizer, create_scheduler, plot_training_history\n",
    "\n",
    "print(\"‚úì Library modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8078302b",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# CONFIGURATION\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "PLM_NAME = 'esm2_35m'  # Options: 'esm2_8m', 'esm2_35m', 'esm2_650m', 'protbert'\n",
    "CNN_TYPE = 'multiscale'  # Options: 'multiscale' or 'deep'\n",
    "RNN_TYPE = 'lstm'  # Options: 'lstm', 'gru', or 'rnn'\n",
    "\n",
    "config = Tier3Config(\n",
    "    # PLM\n",
    "    plm_name=PLM_NAME,\n",
    "    embeddings_path=f'../../data/embeddings/{PLM_NAME}.h5',\n",
    "    \n",
    "    # CNN\n",
    "    cnn_type=CNN_TYPE,\n",
    "    kernel_sizes=[3, 5, 7],\n",
    "    cnn_out_channels=64,\n",
    "    cnn_num_layers=4,\n",
    "    cnn_dilations=[1, 2, 4, 8],\n",
    "    cnn_residual=True,\n",
    "    cnn_dropout=0.0,\n",
    "    \n",
    "    # RNN\n",
    "    rnn_type=RNN_TYPE,\n",
    "    rnn_hidden=256,\n",
    "    rnn_layers=2,\n",
    "    rnn_dropout=0.3,\n",
    "    rnn_bidirectional=True,\n",
    "    \n",
    "    # Head - Try q3guided for this tier!\n",
    "    head_strategy='q3guided',\n",
    "    head_hidden=256,\n",
    "    head_dropout=0.1,\n",
    "    \n",
    "    # Training\n",
    "    max_seq_length=512,\n",
    "    batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    gradient_clip=1.0,\n",
    "    \n",
    "    # Loss\n",
    "    focal_gamma=2.0,\n",
    "    q8_loss_weight=1.0,\n",
    "    q3_loss_weight=0.5,\n",
    "    \n",
    "    # Checkpointing\n",
    "    checkpoint_dir=f'../../checkpoints/tier3_{PLM_NAME}_{CNN_TYPE}_{RNN_TYPE}',\n",
    "    \n",
    "    # Tracking (enabled by default)\n",
    "    use_tracking=True,\n",
    "    experiment_name=f'tier3_{PLM_NAME}_{CNN_TYPE}_{RNN_TYPE}',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d0ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"‚ïê\" * 60)\n",
    "print(\"TIER 3 CNN+RNN CONFIGURATION\")\n",
    "print(\"‚ïê\" * 60)\n",
    "print(f\"\\nüì¶ PLM: {config.plm_name} (dim={get_embedding_dim(config.plm_name)})\")\n",
    "print(f\"\\nüèóÔ∏è  CNN: {config.cnn_type}\")\n",
    "if config.cnn_type == 'multiscale':\n",
    "    print(f\"   Kernels: {config.kernel_sizes}\")\n",
    "else:\n",
    "    print(f\"   Dilations: {config.cnn_dilations}\")\n",
    "print(f\"\\nüîÑ RNN: {config.rnn_type.upper()}\")\n",
    "print(f\"   Hidden: {config.rnn_hidden}\")\n",
    "print(f\"   Layers: {config.rnn_layers}\")\n",
    "print(f\"   Bidirectional: {config.rnn_bidirectional}\")\n",
    "print(f\"   Output dim: {config.rnn_hidden * (2 if config.rnn_bidirectional else 1)}\")\n",
    "print(f\"\\nüéØ Head: {config.head_strategy}\")\n",
    "print(f\"\\nüìä Tracking: {'Enabled' if config.use_tracking else 'Disabled'}\")\n",
    "print(\"‚ïê\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ac02c",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c5958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_path = Path(config.embeddings_path)\n",
    "if not embeddings_path.exists():\n",
    "    print(f\"‚ùå Run: python scripts/extract_embeddings.py --plm {config.plm_name}\")\n",
    "else:\n",
    "    print(f\"‚úì Embeddings: {embeddings_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa09f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = HDF5EmbeddingDataset(\n",
    "    csv_path='../../data/train.csv',\n",
    "    h5_path=config.embeddings_path,\n",
    "    dataset_name='train',\n",
    "    max_length=config.max_seq_length,\n",
    "    exclude_ids=LEAKAGE_TRAIN_IDS,\n",
    ")\n",
    "\n",
    "val_size = int(len(full_dataset) * 0.1)\n",
    "train_size = len(full_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "    collate_fn=collate_fn, num_workers=4, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "    collate_fn=collate_fn, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"üìä Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "print(f\"   Batches: {len(train_loader)} train, {len(val_loader)} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b24846",
   "metadata": {},
   "source": [
    "## 4. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ea3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = get_embedding_dim(config.plm_name)\n",
    "\n",
    "model = Tier3CNNRNN(\n",
    "    embedding_dim=embedding_dim,\n",
    "    # CNN\n",
    "    cnn_type=config.cnn_type,\n",
    "    kernel_sizes=config.kernel_sizes,\n",
    "    cnn_out_channels=config.cnn_out_channels,\n",
    "    cnn_num_layers=config.cnn_num_layers,\n",
    "    cnn_dilations=config.cnn_dilations,\n",
    "    cnn_dropout=config.cnn_dropout,\n",
    "    cnn_residual=config.cnn_residual,\n",
    "    # RNN\n",
    "    rnn_type=config.rnn_type,\n",
    "    rnn_hidden=config.rnn_hidden,\n",
    "    rnn_layers=config.rnn_layers,\n",
    "    rnn_dropout=config.rnn_dropout,\n",
    "    rnn_bidirectional=config.rnn_bidirectional,\n",
    "    # Head\n",
    "    head_strategy=config.head_strategy,\n",
    "    head_hidden=config.head_hidden,\n",
    "    head_dropout=config.head_dropout,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"\\nüèóÔ∏è  Model Summary:\")\n",
    "print(\"‚ïê\" * 60)\n",
    "print(f\"CNN: {config.cnn_type}, output={model.cnn.out_channels}\")\n",
    "print(f\"RNN: {config.rnn_type}, output={model.rnn.out_channels}\")\n",
    "print(f\"Head: {config.head_strategy}\")\n",
    "print(f\"\\nüìà Total Parameters: {model.count_parameters():,}\")\n",
    "print(\"‚ïê\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd3589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RNN types\n",
    "print(\"\\nüìä Parameter Comparison by RNN Type:\")\n",
    "print(\"‚îÄ\" * 45)\n",
    "for rnn_type in ['lstm', 'gru', 'rnn']:\n",
    "    temp_model = Tier3CNNRNN(\n",
    "        embedding_dim=embedding_dim,\n",
    "        cnn_type=config.cnn_type,\n",
    "        kernel_sizes=config.kernel_sizes,\n",
    "        cnn_out_channels=config.cnn_out_channels,\n",
    "        rnn_type=rnn_type,\n",
    "        rnn_hidden=config.rnn_hidden,\n",
    "        rnn_layers=config.rnn_layers,\n",
    "    )\n",
    "    selected = \" ‚Üê selected\" if rnn_type == config.rnn_type else \"\"\n",
    "    print(f\"  {rnn_type.upper():5} ‚îÇ {temp_model.count_parameters():>10,} params{selected}\")\n",
    "    del temp_model\n",
    "print(\"‚îÄ\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c92321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "sample_batch = next(iter(train_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_input = sample_batch['features'].to(DEVICE)\n",
    "    lengths = sample_batch['lengths']\n",
    "    q8_out, q3_out = model(test_input, lengths=lengths)\n",
    "\n",
    "print(f\"\\n‚úì Forward Pass: Input {test_input.shape} ‚Üí Q8 {q8_out.shape}, Q3 {q3_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ecf7e",
   "metadata": {},
   "source": [
    "## 5. Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff44fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = get_multitask_loss(\n",
    "    loss_type='focal',\n",
    "    q8_weight=config.q8_loss_weight,\n",
    "    q3_weight=config.q3_loss_weight,\n",
    "    gamma=config.focal_gamma,\n",
    ")\n",
    "\n",
    "optimizer = create_optimizer(model, lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "scheduler = create_scheduler(optimizer, scheduler_type='cosine', num_epochs=config.max_epochs)\n",
    "\n",
    "print(\"‚úì Loss, optimizer, scheduler configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702e0e4",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=config.checkpoint_dir,\n",
    "    gradient_clip=config.gradient_clip,\n",
    "    use_amp=torch.cuda.is_available(),\n",
    "    use_tracking=config.use_tracking,\n",
    "    experiment_name=config.experiment_name,\n",
    "    training_config=config.__dict__,\n",
    ")\n",
    "\n",
    "print(\"‚úì Trainer initialized\")\n",
    "print(f\"   Checkpoint dir: {config.checkpoint_dir}\")\n",
    "print(f\"   Mixed Precision: {trainer.use_amp}\")\n",
    "print(f\"   Tracking: {trainer.use_tracking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train(\n",
    "    num_epochs=config.max_epochs,\n",
    "    patience=config.patience,\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ada42",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09447f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_history(\n",
    "    history,\n",
    "    save_path=str(Path(config.checkpoint_dir) / 'training_curves.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38445f79",
   "metadata": {},
   "source": [
    "## 8. Evaluation on CB513 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b51b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb513_path = Path(config.embeddings_path)\n",
    "\n",
    "if cb513_path.exists():\n",
    "    try:\n",
    "        cb513_dataset = HDF5EmbeddingDataset(\n",
    "            csv_path='../../data/cb513.csv',\n",
    "            h5_path=config.embeddings_path,\n",
    "            dataset_name='cb513',\n",
    "            max_length=config.max_seq_length,\n",
    "        )\n",
    "        \n",
    "        cb513_loader = DataLoader(\n",
    "            cb513_dataset,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì CB513 test set loaded: {len(cb513_dataset)} samples\")\n",
    "        \n",
    "        # Load best model\n",
    "        best_checkpoint = torch.load(\n",
    "            Path(config.checkpoint_dir) / 'best_model.pt',\n",
    "            map_location=DEVICE\n",
    "        )\n",
    "        model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "        print(f\"‚úì Best model loaded (epoch {best_checkpoint.get('epoch', 'unknown')})\")\n",
    "        \n",
    "        # Evaluate on CB513\n",
    "        original_val_loader = trainer.val_loader\n",
    "        trainer.val_loader = cb513_loader\n",
    "        test_metrics = trainer.validate()\n",
    "        trainer.val_loader = original_val_loader\n",
    "        \n",
    "        print(\"\\n\" + \"‚ïê\" * 60)\n",
    "        print(\"üìä CB513 TEST SET RESULTS\")\n",
    "        print(\"‚ïê\" * 60)\n",
    "        print(f\"   Q8 Accuracy: {test_metrics['q8_accuracy']:.4f}\")\n",
    "        print(f\"   Q3 Accuracy: {test_metrics['q3_accuracy']:.4f}\")\n",
    "        print(f\"   Q8 F1:       {test_metrics['q8_f1']:.4f}\")\n",
    "        print(f\"   Q3 F1:       {test_metrics['q3_f1']:.4f}\")\n",
    "        print(\"‚ïê\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not evaluate on CB513: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è CB513 embeddings not found. Run extraction first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f0861f",
   "metadata": {},
   "source": [
    "## 9. Q3-Guided Analysis\n",
    "\n",
    "If using `q3guided` strategy, analyze how well Q3 guides Q8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.head_strategy == 'q3guided':\n",
    "    print(\"\\nüîç Q3-Guided Strategy Analysis:\")\n",
    "    print(\"‚îÄ\" * 50)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(val_loader))\n",
    "        features = batch['features'].to(DEVICE)\n",
    "        q8_logits, q3_logits = model(features, return_q3=True)\n",
    "        \n",
    "        # Check consistency\n",
    "        consistent = model.head.check_consistency(q8_logits, q3_logits)\n",
    "        mask = batch['sst8'] != -100\n",
    "        valid_consistent = consistent[mask.to(DEVICE)]\n",
    "        \n",
    "        print(f\"   Q8/Q3 Consistency: {valid_consistent.float().mean() * 100:.1f}%\")\n",
    "        print(f\"   (How often Q8 predictions fall within Q3's predicted macro-class)\")\n",
    "        print(\"‚îÄ\" * 50)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Using q3discarding strategy - Q3 is trained but discarded at inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9733f1c7",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3703a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"‚ïê\" * 60)\n",
    "print(f\"üéâ TIER 3 {config.cnn_type.upper()} + {config.rnn_type.upper()} TRAINING COMPLETE\")\n",
    "print(\"‚ïê\" * 60)\n",
    "print(f\"\\nüìà Best Validation Results:\")\n",
    "print(f\"   Harmonic F1: {trainer.best_harmonic_f1:.4f}\")\n",
    "print(f\"   Q8 F1:       {trainer.best_q8_f1:.4f}\")\n",
    "print(f\"   Q8 Accuracy: {trainer.best_q8_accuracy:.4f}\")\n",
    "print(f\"\\nüíæ Checkpoints: {config.checkpoint_dir}\")\n",
    "print(\"‚ïê\" * 60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
