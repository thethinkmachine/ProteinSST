{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650d7d29",
   "metadata": {},
   "source": [
    "# Tier 4: TransConv (Transformer + Dilated CNN) Training\n",
    "\n",
    "This notebook implements training for the **Tier 4** architecture:\n",
    "- **Transformer encoder** for global context via self-attention\n",
    "- **Dilated CNN** for multi-scale local feature extraction\n",
    "- Feature fusion combining both branches\n",
    "\n",
    "## Expected Performance\n",
    "- Q3 Accuracy: ~89-92%\n",
    "- Q8 Accuracy: ~78-83%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da06a9fa",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb054827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Tier4Config, LEAKAGE_TRAIN_IDS\n",
    "from src.data import PLMEmbeddingDataset, collate_fn\n",
    "from src.models.tier4_transconv import TransConv\n",
    "from src.losses import get_multitask_loss\n",
    "from src.metrics import evaluate_model, plot_confusion_matrix\n",
    "from src.training import Trainer, create_optimizer, create_scheduler, plot_training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d545ab7",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292755d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Tier4Config(\n",
    "    # Data\n",
    "    max_seq_length=512,\n",
    "    batch_size=16,  # Smaller batch for larger model\n",
    "    \n",
    "    # Model\n",
    "    embedding_dim=1280,\n",
    "    embeddings_path='../../data/embeddings',\n",
    "    \n",
    "    # Transformer\n",
    "    transformer_dim=512,\n",
    "    num_transformer_layers=4,\n",
    "    num_heads=8,\n",
    "    transformer_dropout=0.1,\n",
    "    \n",
    "    # Dilated CNN\n",
    "    cnn_filters=256,\n",
    "    dilations=[1, 2, 4, 8],\n",
    "    \n",
    "    fc_hidden=256,\n",
    "    fc_dropout=0.2,\n",
    "    \n",
    "    # Training\n",
    "    learning_rate=5e-5,  # Lower LR for transformer\n",
    "    weight_decay=0.01,\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    gradient_clip=1.0,\n",
    "    \n",
    "    # Loss\n",
    "    focal_gamma=2.0,\n",
    "    q8_loss_weight=1.0,\n",
    "    q3_loss_weight=0.5,\n",
    "    \n",
    "    # Checkpointing\n",
    "    checkpoint_dir='../../checkpoints/tier4_transconv',\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {config.model_name}\")\n",
    "print(f\"  Transformer layers: {config.num_transformer_layers}\")\n",
    "print(f\"  Attention heads: {config.num_heads}\")\n",
    "print(f\"  Dilations: {config.dilations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32937e6",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a46aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and split data\n",
    "train_df = pd.read_csv('../../data/train.csv')\n",
    "train_df = train_df[~train_df['id'].isin(LEAKAGE_TRAIN_IDS)].reset_index(drop=True)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "val_size = int(len(train_df) * 0.1)\n",
    "val_indices = np.random.choice(len(train_df), val_size, replace=False)\n",
    "train_indices = [i for i in range(len(train_df)) if i not in val_indices]\n",
    "\n",
    "train_split = train_df.iloc[train_indices].reset_index(drop=True)\n",
    "val_split = train_df.iloc[val_indices].reset_index(drop=True)\n",
    "\n",
    "train_split.to_csv('/tmp/transconv_train.csv', index=False)\n",
    "val_split.to_csv('/tmp/transconv_val.csv', index=False)\n",
    "\n",
    "# Check for embeddings\n",
    "embeddings_dir = Path(config.embeddings_path)\n",
    "if not embeddings_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Embeddings not found at {embeddings_dir}. \"\n",
    "        \"Run scripts/extract_embeddings.py first.\"\n",
    "    )\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PLMEmbeddingDataset(\n",
    "    '/tmp/transconv_train.csv',\n",
    "    config.embeddings_path,\n",
    "    max_length=config.max_seq_length,\n",
    ")\n",
    "\n",
    "val_dataset = PLMEmbeddingDataset(\n",
    "    '/tmp/transconv_val.csv', \n",
    "    config.embeddings_path,\n",
    "    max_length=config.max_seq_length,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ded32a",
   "metadata": {},
   "source": [
    "## 4. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransConv(\n",
    "    embedding_dim=config.embedding_dim,\n",
    "    transformer_dim=config.transformer_dim,\n",
    "    num_transformer_layers=config.num_transformer_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    transformer_dropout=config.transformer_dropout,\n",
    "    cnn_filters=config.cnn_filters,\n",
    "    dilations=config.dilations,\n",
    "    fc_hidden=config.fc_hidden,\n",
    "    fc_dropout=config.fc_dropout,\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {model.count_parameters():,}\")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "sample_batch = next(iter(train_loader))\n",
    "test_input = sample_batch['features'].to(DEVICE)\n",
    "q8_out, q3_out = model(test_input)\n",
    "print(f\"Q8 output shape: {q8_out.shape}\")\n",
    "print(f\"Q3 output shape: {q3_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40268a",
   "metadata": {},
   "source": [
    "## 5. Loss & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af3291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = get_multitask_loss(\n",
    "    loss_type='focal',\n",
    "    q8_weight=config.q8_loss_weight,\n",
    "    q3_weight=config.q3_loss_weight,\n",
    "    gamma=config.focal_gamma,\n",
    ")\n",
    "\n",
    "optimizer = create_optimizer(\n",
    "    model,\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "\n",
    "scheduler = create_scheduler(\n",
    "    optimizer,\n",
    "    scheduler_type='cosine',\n",
    "    num_epochs=config.max_epochs,\n",
    "    warmup_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46627d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=config.checkpoint_dir,\n",
    "    gradient_clip=config.gradient_clip,\n",
    "    use_amp=torch.cuda.is_available(),\n",
    "    use_tracking=True,\n",
    "    experiment_name='tier4_transconv',\n",
    "    hub_model_id='thethinkmachine/ProteinSST-TransConv',\n",
    "    training_config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train(\n",
    "    num_epochs=config.max_epochs,\n",
    "    patience=config.patience,\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1838a7",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e42432",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_history(history, save_path=f'{config.checkpoint_dir}/training_history.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301eb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f'{config.checkpoint_dir}/best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "report = evaluate_model(\n",
    "    model=model,\n",
    "    dataloader=val_loader,\n",
    "    device=DEVICE,\n",
    "    compute_sov=True,\n",
    ")\n",
    "\n",
    "report.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e913151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import SST8_CLASSES, SST3_CLASSES\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    report.q8_confusion_matrix,\n",
    "    SST8_CLASSES,\n",
    "    title='Q8 Confusion Matrix (Tier 4 - TransConv)',\n",
    "    save_path=f'{config.checkpoint_dir}/q8_confusion_matrix.png',\n",
    ")\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    report.q3_confusion_matrix,\n",
    "    SST3_CLASSES,\n",
    "    title='Q3 Confusion Matrix (Tier 4 - TransConv)',\n",
    "    save_path=f'{config.checkpoint_dir}/q3_confusion_matrix.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c0db16",
   "metadata": {},
   "source": [
    "## 7. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dda539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TIER 4 (TransConv) TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBest Results:\")\n",
    "print(f\"  Q8 Accuracy: {report.q8_accuracy:.4f} ({report.q8_accuracy*100:.2f}%)\")\n",
    "print(f\"  Q3 Accuracy: {report.q3_accuracy:.4f} ({report.q3_accuracy*100:.2f}%)\")\n",
    "print(f\"  Q8 Macro F1: {report.q8_macro_f1:.4f}\")\n",
    "print(f\"  Q3 Macro F1: {report.q3_macro_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nTransConv combines:\")\n",
    "print(f\"  - Transformer: Global context via self-attention\")\n",
    "print(f\"  - Dilated CNN: Multi-scale local patterns\")\n",
    "print(f\"  - Near state-of-the-art performance\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
