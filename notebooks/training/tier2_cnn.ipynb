{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6269ae4b",
   "metadata": {},
   "source": [
    "# ğŸ§¬ Tier 2: CNN Model Training\n",
    "\n",
    "This notebook implements the **Tier 2 CNN** architecture for protein secondary structure prediction.\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                           TIER 2: CNN                                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                         â”‚\n",
    "â”‚   PLM Embeddings (L, D_plm)                                             â”‚\n",
    "â”‚          â”‚                                                              â”‚\n",
    "â”‚          â–¼                                                              â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
    "â”‚   â”‚            CNN BLOCK (choose one)               â”‚                   â”‚\n",
    "â”‚   â”‚                                                 â”‚                   â”‚\n",
    "â”‚   â”‚   MultiscaleCNN                 DeepCNN         â”‚                   â”‚\n",
    "â”‚   â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                   â”‚\n",
    "â”‚   â”‚   â”‚k=3â”‚k=5â”‚k=7â”‚k=11            â”‚ Conv d=1  â”‚    â”‚                   â”‚\n",
    "â”‚   â”‚   â””â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”´â”€â”¬â”€â”˜            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                   â”‚\n",
    "â”‚   â”‚     â””â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”˜              â”‚ Conv d=2  â”‚    â”‚                   â”‚\n",
    "â”‚   â”‚         â”‚concat                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                   â”‚\n",
    "â”‚   â”‚         â–¼                      â”‚ Conv d=4  â”‚    â”‚                   â”‚\n",
    "â”‚   â”‚   (L, 4*64=256)                â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚                   â”‚\n",
    "â”‚   â”‚                                â”‚ Conv d=8  â”‚    â”‚                   â”‚\n",
    "â”‚   â”‚                                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â”‚                   â”‚\n",
    "â”‚   â”‚                                      â–¼          â”‚                   â”‚\n",
    "â”‚   â”‚                                 (L, 256)        â”‚                   â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
    "â”‚                        â”‚                                                â”‚\n",
    "â”‚                        â–¼                                                â”‚\n",
    "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
    "â”‚   â”‚  MTL Head (q3discarding OR q3guided)            â”‚                   â”‚\n",
    "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "## CNN Block Types\n",
    "\n",
    "| Type | Description | Params | Best For |\n",
    "|------|-------------|--------|----------|\n",
    "| **MultiscaleCNN** | Parallel branches, different kernel sizes | ~840K | Local patterns |\n",
    "| **DeepCNN** | Stacked layers, increasing dilation | ~275K | Long-range context |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752cdbf",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ğŸ–¥ï¸  Device: {DEVICE}\")\n",
    "if DEVICE == 'cuda':\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17312bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    Tier2Config, LEAKAGE_TRAIN_IDS,\n",
    "    get_embedding_dim, PLM_EMBEDDING_DIMS,\n",
    ")\n",
    "from src.data import HDF5EmbeddingDataset, collate_fn\n",
    "from src.models import Tier2CNN, SequenceDataset, collate_fn_sequences\n",
    "from src.losses import get_multitask_loss\n",
    "from src.training import Trainer, create_optimizer, create_scheduler, plot_training_history\n",
    "\n",
    "print(\"âœ“ Library modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9a977f",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57731991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "PLM_NAME = 'protbert'  # Options: 'esm2_8m', 'esm2_35m', 'esm2_650m', 'protbert'\n",
    "CNN_TYPE = 'multiscale'  # Options: 'multiscale' or 'deep'\n",
    "\n",
    "# Generate submission.csv from test.csv using trained model\n",
    "GENERATE_SUBMISSION = True\n",
    "\n",
    "# FFT Mode: Set False to train PLM end-to-end (requires more GPU memory)\n",
    "# When True, uses pre-extracted frozen embeddings (default, memory efficient)\n",
    "FROZEN_PLM = True\n",
    "\n",
    "config = Tier2Config(\n",
    "    # PLM Selection\n",
    "    plm_name=PLM_NAME,\n",
    "    embeddings_path=f'../../data/embeddings/{PLM_NAME}.h5',\n",
    "    \n",
    "    # Training Mode\n",
    "    frozen_plm=FROZEN_PLM,\n",
    "    gradient_checkpointing=not FROZEN_PLM,  # Enable for FFT to save memory\n",
    "    \n",
    "    # CNN Architecture\n",
    "    cnn_type=CNN_TYPE,\n",
    "    \n",
    "    # MultiscaleCNN params\n",
    "    kernel_sizes=[3, 5, 7, 11],\n",
    "    cnn_out_channels=64,\n",
    "    \n",
    "    # DeepCNN params\n",
    "    cnn_num_layers=4,\n",
    "    cnn_dilations=[1, 2, 4, 8],\n",
    "    cnn_residual=True,\n",
    "    \n",
    "    # Common\n",
    "    cnn_activation='relu',\n",
    "    cnn_dropout=0.0,\n",
    "    \n",
    "    # MTL Head\n",
    "    head_strategy='q3guided',\n",
    "    head_hidden=256,\n",
    "    head_dropout=0.1,\n",
    "    \n",
    "    # Training - adjusted for mode\n",
    "    max_seq_length=512,\n",
    "    batch_size=8 if not FROZEN_PLM else 32,  # Smaller batch for FFT\n",
    "    learning_rate=1e-5 if not FROZEN_PLM else 1e-4,  # Lower LR for FFT\n",
    "    weight_decay=0.01,\n",
    "    max_epochs=20 if not FROZEN_PLM else 50,  # Fewer epochs for FFT\n",
    "    patience=5 if not FROZEN_PLM else 10,\n",
    "    gradient_clip=1.0,\n",
    "    \n",
    "    # Loss - Options: 'focal', 'weighted_ce', 'label_smoothing', 'ce', 'crf'\n",
    "    loss_type='focal',  # Use 'crf' for CRF Negative Log-Likelihood\n",
    "    focal_gamma=1.0,\n",
    "    q8_loss_weight=1.0,\n",
    "    q3_loss_weight=0.5,\n",
    "    \n",
    "    # Checkpointing\n",
    "    checkpoint_dir=f'../../checkpoints/tier2_{PLM_NAME}_{CNN_TYPE}' + ('_fft' if not FROZEN_PLM else ''),\n",
    "    \n",
    "    # Tracking (enabled by default)\n",
    "    use_tracking=True,\n",
    "    trackio_space_id='thethinkmachine/trackio',\n",
    "    hub_model_id=f'thethinkmachine/ProteinSST-{PLM_NAME}-{CNN_TYPE}' + ('-fft' if not FROZEN_PLM else ''),\n",
    "    experiment_name=f'tier2_{PLM_NAME}_{CNN_TYPE}' + ('_fft' if not FROZEN_PLM else ''),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9081ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"â•\" * 60)\n",
    "print(f\"TIER 2 CNN CONFIGURATION ({CNN_TYPE.upper()})\")\n",
    "print(\"â•\" * 60)\n",
    "print(f\"\\nğŸ”§ Mode: {'Frozen PLM' if config.frozen_plm else 'ğŸ”¥ Full Fine-Tuning (FFT)'}\")\n",
    "print(f\"ğŸ“¦ PLM: {config.plm_name}\")\n",
    "print(f\"   Embedding Dim: {get_embedding_dim(config.plm_name)}\")\n",
    "print(f\"\\nğŸ—ï¸  CNN Architecture:\")\n",
    "print(f\"   Type: {config.cnn_type}\")\n",
    "if config.cnn_type == 'multiscale':\n",
    "    print(f\"   Kernel Sizes: {config.kernel_sizes}\")\n",
    "    print(f\"   Channels per Branch: {config.cnn_out_channels}\")\n",
    "    print(f\"   Total Output: {config.cnn_out_channels * len(config.kernel_sizes)}\")\n",
    "else:\n",
    "    print(f\"   Layers: {config.cnn_num_layers}\")\n",
    "    print(f\"   Dilations: {config.cnn_dilations}\")\n",
    "    print(f\"   Residual: {config.cnn_residual}\")\n",
    "print(f\"\\nğŸ¯ Head Strategy: {config.head_strategy}\")\n",
    "print(f\"\\nâš¡ Training Settings:\")\n",
    "print(f\"   Batch Size: {config.batch_size}\")\n",
    "print(f\"   Learning Rate: {config.learning_rate}\")\n",
    "print(f\"   Max Epochs: {config.max_epochs}\")\n",
    "print(f\"\\nğŸ“Š Tracking: {'Enabled' if config.use_tracking else 'Disabled'}\")\n",
    "print(\"â•\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef5268",
   "metadata": {},
   "source": [
    "## 3. Data Loading\n",
    "\n",
    "- **Frozen mode**: Load pre-computed PLM embeddings from HDF5 file\n",
    "- **FFT mode**: Load raw sequences (PLM processes them on-the-fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4add44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.frozen_plm:\n",
    "    embeddings_path = Path(config.embeddings_path)\n",
    "    if not embeddings_path.exists():\n",
    "        print(f\"âŒ Run: python scripts/extract_embeddings.py --plm {config.plm_name}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Embeddings: {embeddings_path}\")\n",
    "else:\n",
    "    print(\"ğŸ”¥ FFT Mode: PLM will be trained end-to-end\")\n",
    "    print(f\"   PLM: {config.plm_name}\")\n",
    "    print(f\"   Gradient Checkpointing: {config.gradient_checkpointing}\")\n",
    "    embeddings_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "\n",
    "if config.frozen_plm:\n",
    "    full_dataset = HDF5EmbeddingDataset(\n",
    "        csv_path='../../data/train.csv',\n",
    "        h5_path=config.embeddings_path,\n",
    "        dataset_name='train',\n",
    "        max_length=config.max_seq_length,\n",
    "        exclude_ids=LEAKAGE_TRAIN_IDS,\n",
    "    )\n",
    "    current_collate_fn = collate_fn\n",
    "else:\n",
    "    full_dataset = SequenceDataset(\n",
    "        csv_path='../../data/train.csv',\n",
    "        max_length=config.max_seq_length,\n",
    "        exclude_ids=LEAKAGE_TRAIN_IDS,\n",
    "    )\n",
    "    current_collate_fn = collate_fn_sequences\n",
    "\n",
    "val_size = int(len(full_dataset) * 0.1)\n",
    "train_size = len(full_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=config.batch_size, shuffle=True,\n",
    "    collate_fn=current_collate_fn, num_workers=4 if config.frozen_plm else 0, pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=config.batch_size, shuffle=False,\n",
    "    collate_fn=current_collate_fn, num_workers=4 if config.frozen_plm else 0, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Train: {len(train_dataset)}, Val: {len(val_dataset)}\")\n",
    "print(f\"   Batches: {len(train_loader)} train, {len(val_loader)} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ded7c4",
   "metadata": {},
   "source": [
    "## 4. Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = get_embedding_dim(config.plm_name)\n",
    "\n",
    "model = Tier2CNN(\n",
    "    embedding_dim=embedding_dim,\n",
    "    cnn_type=config.cnn_type,\n",
    "    kernel_sizes=config.kernel_sizes,\n",
    "    cnn_out_channels=config.cnn_out_channels,\n",
    "    cnn_num_layers=config.cnn_num_layers,\n",
    "    cnn_dilations=config.cnn_dilations,\n",
    "    cnn_activation=config.cnn_activation,\n",
    "    cnn_dropout=config.cnn_dropout,\n",
    "    cnn_residual=config.cnn_residual,\n",
    "    head_strategy=config.head_strategy,\n",
    "    head_hidden=config.head_hidden,\n",
    "    head_dropout=config.head_dropout,\n",
    "    frozen_plm=config.frozen_plm,\n",
    "    plm_name=config.plm_name,\n",
    "    gradient_checkpointing=config.gradient_checkpointing,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(\"\\nğŸ—ï¸  Model Summary:\")\n",
    "print(\"â•\" * 60)\n",
    "print(f\"Mode: {'Frozen PLM' if config.frozen_plm else 'ğŸ”¥ Full Fine-Tuning (FFT)'}\")\n",
    "print(f\"PLM: {config.plm_name}\")\n",
    "print(f\"CNN Type: {config.cnn_type}\")\n",
    "print(f\"CNN Output Channels: {model.cnn.out_channels}\")\n",
    "\n",
    "if config.frozen_plm:\n",
    "    print(f\"\\nğŸ“ˆ Total Parameters: {model.count_parameters():,}\")\n",
    "else:\n",
    "    total_params = model.count_parameters()\n",
    "    head_params = model.count_head_parameters()\n",
    "    plm_params = total_params - head_params\n",
    "    print(f\"\\nğŸ“ˆ Parameter Breakdown:\")\n",
    "    print(f\"   PLM Backbone: {plm_params:,} (trainable)\")\n",
    "    print(f\"   Head Layers:  {head_params:,}\")\n",
    "    print(f\"   Total:        {total_params:,}\")\n",
    "print(\"â•\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80fbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with alt CNN type (only in frozen mode to save memory)\n",
    "if config.frozen_plm:\n",
    "    alt_type = 'deep' if config.cnn_type == 'multiscale' else 'multiscale'\n",
    "    alt_model = Tier2CNN(\n",
    "        embedding_dim=embedding_dim,\n",
    "        cnn_type=alt_type,\n",
    "        kernel_sizes=config.kernel_sizes,\n",
    "        cnn_out_channels=config.cnn_out_channels,\n",
    "        cnn_num_layers=config.cnn_num_layers,\n",
    "        cnn_dilations=config.cnn_dilations,\n",
    "    )\n",
    "\n",
    "    print(\"\\nğŸ“Š CNN Type Comparison:\")\n",
    "    print(\"â”€\" * 40)\n",
    "    print(f\"  {config.cnn_type:12} â”‚ {model.count_parameters():,} params â† selected\")\n",
    "    print(f\"  {alt_type:12} â”‚ {alt_model.count_parameters():,} params\")\n",
    "    print(\"â”€\" * 40)\n",
    "    del alt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc42e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "sample_batch = next(iter(train_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if config.frozen_plm:\n",
    "        test_input = sample_batch['features'].to(DEVICE)\n",
    "        q8_out, q3_out = model(test_input)\n",
    "        print(f\"\\nâœ“ Forward Pass: Input {test_input.shape} â†’ Q8 {q8_out.shape}, Q3 {q3_out.shape}\")\n",
    "    else:\n",
    "        test_seqs = sample_batch['sequences']\n",
    "        q8_out, q3_out = model(sequences=test_seqs)\n",
    "        print(f\"\\nâœ“ Forward Pass: Input {len(test_seqs)} seqs â†’ Q8 {q8_out.shape}, Q3 {q3_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481002ed",
   "metadata": {},
   "source": [
    "## 5. Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-task loss\n",
    "# Options: 'focal' (default), 'weighted_ce', 'label_smoothing', 'ce', 'crf'\n",
    "loss_fn = get_multitask_loss(\n",
    "    loss_type=config.loss_type,\n",
    "    q8_weight=config.q8_loss_weight,\n",
    "    q3_weight=config.q3_loss_weight,\n",
    "    gamma=config.focal_gamma,\n",
    ")\n",
    "\n",
    "optimizer = create_optimizer(model, lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "scheduler = create_scheduler(optimizer, scheduler_type='cosine', num_epochs=config.max_epochs)\n",
    "\n",
    "print(f\"âœ“ Loss ({config.loss_type}), optimizer, scheduler configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a6f06",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e739aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=config.checkpoint_dir,\n",
    "    gradient_clip=config.gradient_clip,\n",
    "    use_amp=torch.cuda.is_available(),\n",
    "    frozen_plm=FROZEN_PLM,\n",
    "    use_tracking=config.use_tracking,\n",
    "    trackio_space_id=config.trackio_space_id,\n",
    "    hub_model_id=config.hub_model_id,\n",
    "    experiment_name=config.experiment_name,\n",
    "    training_config=config.__dict__,\n",
    ")\n",
    "\n",
    "print(\"âœ“ Trainer initialized\")\n",
    "print(f\"   Checkpoint dir: {config.checkpoint_dir}\")\n",
    "print(f\"   Mixed Precision: {trainer.use_amp}\")\n",
    "print(f\"   Tracking: {trainer.use_tracking}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.train(\n",
    "    num_epochs=config.max_epochs,\n",
    "    patience=config.patience,\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af08de",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a34aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_history(\n",
    "    history,\n",
    "    save_path=str(Path(config.checkpoint_dir) / 'training_curves.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c4cd68",
   "metadata": {},
   "source": [
    "## 8. Evaluation on CB513 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274048b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.frozen_plm:\n",
    "    cb513_path = Path(config.embeddings_path)\n",
    "    cb513_available = cb513_path.exists()\n",
    "else:\n",
    "    cb513_available = Path('../../data/cb513.csv').exists()\n",
    "\n",
    "if cb513_available:\n",
    "    try:\n",
    "        if config.frozen_plm:\n",
    "            cb513_dataset = HDF5EmbeddingDataset(\n",
    "                csv_path='../../data/cb513.csv',\n",
    "                h5_path=config.embeddings_path,\n",
    "                dataset_name='cb513',\n",
    "                max_length=config.max_seq_length,\n",
    "            )\n",
    "            cb513_collate = collate_fn\n",
    "        else:\n",
    "            cb513_dataset = SequenceDataset(\n",
    "                csv_path='../../data/cb513.csv',\n",
    "                max_length=config.max_seq_length,\n",
    "            )\n",
    "            cb513_collate = collate_fn_sequences\n",
    "        \n",
    "        cb513_loader = DataLoader(\n",
    "            cb513_dataset,\n",
    "            batch_size=config.batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=cb513_collate,\n",
    "            num_workers=4 if config.frozen_plm else 0,\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ CB513 test set loaded: {len(cb513_dataset)} samples\")\n",
    "        \n",
    "        # Load best model\n",
    "        best_checkpoint = torch.load(\n",
    "            Path(config.checkpoint_dir) / 'best_model.pt',\n",
    "            map_location=DEVICE\n",
    "        )\n",
    "        model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "        print(f\"âœ“ Best model loaded (epoch {best_checkpoint.get('epoch', 'unknown')})\")\n",
    "        \n",
    "        # Evaluate on CB513\n",
    "        original_val_loader = trainer.val_loader\n",
    "        trainer.val_loader = cb513_loader\n",
    "        test_metrics = trainer.validate()\n",
    "        trainer.val_loader = original_val_loader\n",
    "        \n",
    "        print(\"\\n\" + \"â•\" * 60)\n",
    "        print(\"ğŸ“Š CB513 TEST SET RESULTS\")\n",
    "        print(\"â•\" * 60)\n",
    "        print(f\"   Q8 Accuracy: {test_metrics['q8_accuracy']:.4f}\")\n",
    "        print(f\"   Q3 Accuracy: {test_metrics['q3_accuracy']:.4f}\")\n",
    "        print(f\"   Q8 F1:       {test_metrics['q8_f1']:.4f}\")\n",
    "        print(f\"   Q3 F1:       {test_metrics['q3_f1']:.4f}\")\n",
    "        print(\"â•\" * 60)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not evaluate on CB513: {e}\")\n",
    "else:\n",
    "    if config.frozen_plm:\n",
    "        print(\"âš ï¸ CB513 embeddings not found. Run extraction first.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ CB513 CSV not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe5c0d",
   "metadata": {},
   "source": [
    "## 9. Generate Submission (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1800c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_SUBMISSION:\n",
    "    from src.config import IDX_TO_SST8\n",
    "    import pandas as pd\n",
    "    \n",
    "    print(\"\\n\" + \"â•\" * 60)\n",
    "    print(\"ğŸ“ GENERATING SUBMISSION\")\n",
    "    print(\"â•\" * 60)\n",
    "    \n",
    "    # Check if test data exists\n",
    "    test_csv_path = Path('../../data/test.csv')\n",
    "    \n",
    "    if not test_csv_path.exists():\n",
    "        print(f\"âŒ Test CSV not found: {test_csv_path}\")\n",
    "    elif config.frozen_plm and not Path(config.embeddings_path).exists():\n",
    "        print(f\"âŒ Embeddings not found: {config.embeddings_path}\")\n",
    "    else:\n",
    "        try:\n",
    "            # Load test dataset\n",
    "            if config.frozen_plm:\n",
    "                test_dataset = HDF5EmbeddingDataset(\n",
    "                    csv_path=str(test_csv_path),\n",
    "                    h5_path=config.embeddings_path,\n",
    "                    dataset_name='test',\n",
    "                    max_length=config.max_seq_length,\n",
    "                    is_test=True,\n",
    "                )\n",
    "                test_collate = collate_fn\n",
    "            else:\n",
    "                test_dataset = SequenceDataset(\n",
    "                    csv_path=str(test_csv_path),\n",
    "                    max_length=config.max_seq_length,\n",
    "                    is_test=True,\n",
    "                )\n",
    "                test_collate = collate_fn_sequences\n",
    "            \n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=config.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=test_collate,\n",
    "                num_workers=4 if config.frozen_plm else 0,\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ“ Test set loaded: {len(test_dataset)} samples\")\n",
    "            \n",
    "            # Load best model\n",
    "            best_checkpoint = torch.load(\n",
    "                Path(config.checkpoint_dir) / 'best_model.pt',\n",
    "                map_location=DEVICE\n",
    "            )\n",
    "            model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "            model.eval()\n",
    "            print(f\"âœ“ Best model loaded (epoch {best_checkpoint.get('epoch', 'unknown')})\")\n",
    "            \n",
    "            # Generate predictions\n",
    "            all_ids = []\n",
    "            all_preds = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    lengths = batch['lengths']\n",
    "                    ids = batch['ids']\n",
    "                    \n",
    "                    if config.frozen_plm:\n",
    "                        features = batch['features'].to(DEVICE)\n",
    "                        q8_logits, _ = model(features, return_q3=False)\n",
    "                    else:\n",
    "                        sequences = batch['sequences']\n",
    "                        q8_logits, _ = model(sequences=sequences, return_q3=False)\n",
    "                    \n",
    "                    q8_preds = q8_logits.argmax(dim=-1)  # (batch, seq_len)\n",
    "                    \n",
    "                    for i, (sample_id, length) in enumerate(zip(ids, lengths)):\n",
    "                        pred_indices = q8_preds[i, :length].cpu().numpy()\n",
    "                        pred_str = ''.join([IDX_TO_SST8[idx] for idx in pred_indices])\n",
    "                        all_ids.append(sample_id)\n",
    "                        all_preds.append(pred_str)\n",
    "            \n",
    "            # Create submission DataFrame\n",
    "            submission_df = pd.DataFrame({\n",
    "                'id': all_ids,\n",
    "                'sst8': all_preds,\n",
    "            })\n",
    "            \n",
    "            # Save submission\n",
    "            submission_path = Path(config.checkpoint_dir) / 'submission.csv'\n",
    "            submission_df.to_csv(submission_path, index=False)\n",
    "            \n",
    "            print(f\"\\nâœ“ Submission saved: {submission_path}\")\n",
    "            print(f\"   Total predictions: {len(submission_df)}\")\n",
    "            print(f\"\\n   Preview:\")\n",
    "            print(submission_df.head())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Could not generate submission: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "else:\n",
    "    print(\"â„¹ï¸  Submission generation disabled. Set GENERATE_SUBMISSION = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02136c6",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe56ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"â•\" * 60)\n",
    "print(f\"ğŸ‰ TIER 2 {config.cnn_type.upper()} CNN TRAINING COMPLETE\")\n",
    "print(\"â•\" * 60)\n",
    "print(f\"\\nğŸ”§ Training Mode: {'Frozen PLM' if config.frozen_plm else 'ğŸ”¥ Full Fine-Tuning (FFT)'}\")\n",
    "print(f\"   PLM: {config.plm_name}\")\n",
    "print(f\"\\nğŸ“ˆ Best Validation Results:\")\n",
    "print(f\"   Harmonic F1: {trainer.best_harmonic_f1:.4f}\")\n",
    "print(f\"   Q8 F1:       {trainer.best_q8_f1:.4f}\")\n",
    "print(f\"   Q8 Accuracy: {trainer.best_q8_accuracy:.4f}\")\n",
    "print(f\"\\nğŸ’¾ Checkpoints: {config.checkpoint_dir}\")\n",
    "print(\"â•\" * 60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
