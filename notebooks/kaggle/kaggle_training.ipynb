{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe06f77",
   "metadata": {},
   "source": [
    "# ğŸ§¬ ProteinSST - Kaggle Training Notebook\n",
    "\n",
    "This notebook is designed for the **Kaggle Protein Secondary Structure Prediction** competition.\n",
    "\n",
    "## Quick Start\n",
    "1. Upload `src/` folder as a Kaggle Dataset (or use the cell below to install)\n",
    "2. Upload pre-extracted embeddings as a Kaggle Dataset (or extract them here)\n",
    "3. Configure the TIER and hyperparameters\n",
    "4. Run all cells to train and generate `submission.csv`\n",
    "\n",
    "## Architecture Tiers\n",
    "\n",
    "| Tier | Architecture | Parameters | Best For |\n",
    "|------|-------------|------------|----------|\n",
    "| 1 | PLM â†’ FC â†’ Head | ~500K | Fast baseline |\n",
    "| 2 | PLM â†’ CNN â†’ Head | ~800K | Local patterns |\n",
    "| 3 | PLM â†’ CNN â†’ RNN â†’ Head | ~2M | Sequential dependencies |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd9aaf",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50952288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# KAGGLE SETUP - Run this cell first!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Option 1: If you uploaded src/ as a dataset named 'proteinsst-src'\n",
    "# import sys\n",
    "# sys.path.insert(0, '/kaggle/input/proteinsst-src')\n",
    "\n",
    "# Option 2: Clone from GitHub (uncomment if needed)\n",
    "!git clone https://github.com/thethinkmachine/ProteinSST.git\n",
    "# import sys\n",
    "# sys.path.insert(0, '/kaggle/working/ProteinSST')\n",
    "\n",
    "# For local testing, use this:\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "# Install dependencies (if not already installed)\n",
    "!pip install -q h5py transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03894ae6",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**âš ï¸ IMPORTANT: Configure these settings before running!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ MAIN CONFIGURATION - CHANGE THESE!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Model Selection\n",
    "TIER = 1  # Options: 1 (baseline), 2 (CNN), 3 (CNN+RNN)\n",
    "PLM_NAME = 'protbert'  # Options: 'protbert', 'esm2_8m', 'esm2_35m', 'esm2_650m'\n",
    "\n",
    "# Architecture Options (Tier 2 & 3 only)\n",
    "CNN_TYPE = 'multiscale'  # Options: 'multiscale', 'deep'\n",
    "RNN_TYPE = 'lstm'  # Options: 'lstm', 'gru', 'rnn' (Tier 3 only)\n",
    "\n",
    "# Training Settings\n",
    "LOSS_TYPE = 'focal'  # Options: 'focal', 'crf', 'weighted_ce', 'ce'\n",
    "HEAD_STRATEGY = 'q3guided'  # Options: 'q3guided', 'q3discarding'\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "\n",
    "# Output\n",
    "GENERATE_SUBMISSION = True\n",
    "SEED = 42\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“ PATHS - Adjust for your Kaggle datasets\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# For Kaggle:\n",
    "# TRAIN_CSV = '/kaggle/input/your-competition-name/train.csv'\n",
    "# TEST_CSV = '/kaggle/input/your-competition-name/test.csv'\n",
    "# EMBEDDINGS_PATH = '/kaggle/input/proteinsst-embeddings/protbert.h5'\n",
    "# OUTPUT_DIR = '/kaggle/working'\n",
    "\n",
    "# For local testing:\n",
    "TRAIN_CSV = '../../data/train.csv'\n",
    "TEST_CSV = '../../data/test.csv'\n",
    "EMBEDDINGS_PATH = f'../../data/embeddings/{PLM_NAME}.h5'\n",
    "OUTPUT_DIR = '../../checkpoints/kaggle'\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\n{'â•' * 60}\")\n",
    "print(f\"CONFIGURATION SUMMARY\")\n",
    "print(f\"{'â•' * 60}\")\n",
    "print(f\"ğŸ—ï¸  Tier: {TIER}\")\n",
    "print(f\"ğŸ“¦ PLM: {PLM_NAME}\")\n",
    "if TIER >= 2:\n",
    "    print(f\"ğŸ”² CNN: {CNN_TYPE}\")\n",
    "if TIER >= 3:\n",
    "    print(f\"ğŸ”„ RNN: {RNN_TYPE}\")\n",
    "print(f\"ğŸ“‰ Loss: {LOSS_TYPE}\")\n",
    "print(f\"ğŸ¯ Head: {HEAD_STRATEGY}\")\n",
    "print(f\"ğŸ–¥ï¸  Device: {DEVICE}\")\n",
    "print(f\"{'â•' * 60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea6f30",
   "metadata": {},
   "source": [
    "## 3. Import ProteinSST Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import (\n",
    "    Tier1Config, Tier2Config, Tier3Config,\n",
    "    LEAKAGE_TRAIN_IDS, get_embedding_dim, IDX_TO_SST8,\n",
    ")\n",
    "from src.data import HDF5EmbeddingDataset, collate_fn\n",
    "from src.models import Tier1Baseline, Tier2CNN, Tier3CNNRNN\n",
    "from src.losses import get_multitask_loss\n",
    "from src.training import Trainer, create_optimizer, create_scheduler\n",
    "\n",
    "print(\"âœ“ ProteinSST modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885be2b3",
   "metadata": {},
   "source": [
    "## 4. Create Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build config based on selected tier\n",
    "embedding_dim = get_embedding_dim(PLM_NAME)\n",
    "\n",
    "if TIER == 1:\n",
    "    config = Tier1Config(\n",
    "        plm_name=PLM_NAME,\n",
    "        embeddings_path=EMBEDDINGS_PATH,\n",
    "        fc_hidden=512,\n",
    "        fc_dropout=0.1,\n",
    "        head_strategy=HEAD_STRATEGY,\n",
    "        head_hidden=256,\n",
    "        head_dropout=0.1,\n",
    "        max_seq_length=512,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        gradient_clip=1.0,\n",
    "        loss_type=LOSS_TYPE,\n",
    "        focal_gamma=1.0,\n",
    "        q8_loss_weight=1.0,\n",
    "        q3_loss_weight=0.5,\n",
    "        checkpoint_dir=OUTPUT_DIR,\n",
    "        use_tracking=False,  # Disable for Kaggle\n",
    "    )\n",
    "    ModelClass = Tier1Baseline\n",
    "\n",
    "elif TIER == 2:\n",
    "    config = Tier2Config(\n",
    "        plm_name=PLM_NAME,\n",
    "        embeddings_path=EMBEDDINGS_PATH,\n",
    "        cnn_type=CNN_TYPE,\n",
    "        kernel_sizes=[3, 5, 7, 11],\n",
    "        cnn_out_channels=64,\n",
    "        cnn_num_layers=4,\n",
    "        cnn_dilations=[1, 2, 4, 8],\n",
    "        cnn_residual=True,\n",
    "        cnn_dropout=0.0,\n",
    "        head_strategy=HEAD_STRATEGY,\n",
    "        head_hidden=256,\n",
    "        head_dropout=0.1,\n",
    "        max_seq_length=512,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        gradient_clip=1.0,\n",
    "        loss_type=LOSS_TYPE,\n",
    "        focal_gamma=1.0,\n",
    "        q8_loss_weight=1.0,\n",
    "        q3_loss_weight=0.5,\n",
    "        checkpoint_dir=OUTPUT_DIR,\n",
    "        use_tracking=False,\n",
    "    )\n",
    "    ModelClass = Tier2CNN\n",
    "\n",
    "elif TIER == 3:\n",
    "    config = Tier3Config(\n",
    "        plm_name=PLM_NAME,\n",
    "        embeddings_path=EMBEDDINGS_PATH,\n",
    "        skip_cnn=False,\n",
    "        cnn_type=CNN_TYPE,\n",
    "        kernel_sizes=[3, 5, 7],\n",
    "        cnn_out_channels=64,\n",
    "        cnn_num_layers=4,\n",
    "        cnn_dilations=[1, 2, 4, 8],\n",
    "        cnn_residual=True,\n",
    "        cnn_dropout=0.0,\n",
    "        rnn_type=RNN_TYPE,\n",
    "        rnn_hidden=256,\n",
    "        rnn_layers=2,\n",
    "        rnn_dropout=0.3,\n",
    "        rnn_bidirectional=True,\n",
    "        head_strategy=HEAD_STRATEGY,\n",
    "        head_hidden=256,\n",
    "        head_dropout=0.1,\n",
    "        max_seq_length=512,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        patience=PATIENCE,\n",
    "        gradient_clip=1.0,\n",
    "        loss_type=LOSS_TYPE,\n",
    "        focal_gamma=1.0,\n",
    "        q8_loss_weight=1.0,\n",
    "        q3_loss_weight=0.5,\n",
    "        checkpoint_dir=OUTPUT_DIR,\n",
    "        use_tracking=False,\n",
    "    )\n",
    "    ModelClass = Tier3CNNRNN\n",
    "\n",
    "print(f\"âœ“ Tier {TIER} config created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71841b8",
   "metadata": {},
   "source": [
    "## 5. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embeddings exist\n",
    "embeddings_path = Path(EMBEDDINGS_PATH)\n",
    "if not embeddings_path.exists():\n",
    "    print(f\"âŒ Embeddings not found: {embeddings_path}\")\n",
    "    print(f\"\\n   You need to either:\")\n",
    "    print(f\"   1. Upload pre-extracted embeddings as a Kaggle dataset\")\n",
    "    print(f\"   2. Run the embedding extraction cell below\")\n",
    "else:\n",
    "    import h5py\n",
    "    with h5py.File(embeddings_path, 'r') as f:\n",
    "        train_count = len(f['train']) if 'train' in f else 0\n",
    "        test_count = len(f['test']) if 'test' in f else 0\n",
    "        plm_name = f.attrs.get('plm_name', 'unknown')\n",
    "        emb_dim = f.attrs.get('embedding_dim', 0)\n",
    "    \n",
    "    print(f\"âœ“ Embeddings found: {embeddings_path}\")\n",
    "    print(f\"   PLM: {plm_name}, Dim: {emb_dim}\")\n",
    "    print(f\"   Train: {train_count}, Test: {test_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "\n",
    "full_dataset = HDF5EmbeddingDataset(\n",
    "    csv_path=TRAIN_CSV,\n",
    "    h5_path=EMBEDDINGS_PATH,\n",
    "    dataset_name='train',\n",
    "    max_length=config.max_seq_length,\n",
    "    exclude_ids=LEAKAGE_TRAIN_IDS,\n",
    ")\n",
    "\n",
    "# Train/Val split\n",
    "val_size = int(len(full_dataset) * 0.1)\n",
    "train_size = len(full_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset Split:\")\n",
    "print(f\"   Train: {len(train_dataset):,} samples ({len(train_loader)} batches)\")\n",
    "print(f\"   Val:   {len(val_dataset):,} samples ({len(val_loader)} batches)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49bc53e",
   "metadata": {},
   "source": [
    "## 6. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model based on tier\n",
    "if TIER == 1:\n",
    "    model = ModelClass(\n",
    "        embedding_dim=embedding_dim,\n",
    "        fc_hidden=config.fc_hidden,\n",
    "        fc_dropout=config.fc_dropout,\n",
    "        head_strategy=config.head_strategy,\n",
    "        head_hidden=config.head_hidden,\n",
    "        head_dropout=config.head_dropout,\n",
    "    )\n",
    "    \n",
    "elif TIER == 2:\n",
    "    model = ModelClass(\n",
    "        embedding_dim=embedding_dim,\n",
    "        cnn_type=config.cnn_type,\n",
    "        kernel_sizes=config.kernel_sizes,\n",
    "        cnn_out_channels=config.cnn_out_channels,\n",
    "        cnn_num_layers=config.cnn_num_layers,\n",
    "        cnn_dilations=config.cnn_dilations,\n",
    "        cnn_activation='relu',\n",
    "        cnn_dropout=config.cnn_dropout,\n",
    "        cnn_residual=config.cnn_residual,\n",
    "        head_strategy=config.head_strategy,\n",
    "        head_hidden=config.head_hidden,\n",
    "        head_dropout=config.head_dropout,\n",
    "    )\n",
    "    \n",
    "elif TIER == 3:\n",
    "    model = ModelClass(\n",
    "        embedding_dim=embedding_dim,\n",
    "        skip_cnn=config.skip_cnn,\n",
    "        cnn_type=config.cnn_type,\n",
    "        kernel_sizes=config.kernel_sizes,\n",
    "        cnn_out_channels=config.cnn_out_channels,\n",
    "        cnn_num_layers=config.cnn_num_layers,\n",
    "        cnn_dilations=config.cnn_dilations,\n",
    "        cnn_dropout=config.cnn_dropout,\n",
    "        cnn_residual=config.cnn_residual,\n",
    "        rnn_type=config.rnn_type,\n",
    "        rnn_hidden=config.rnn_hidden,\n",
    "        rnn_layers=config.rnn_layers,\n",
    "        rnn_dropout=config.rnn_dropout,\n",
    "        rnn_bidirectional=config.rnn_bidirectional,\n",
    "        head_strategy=config.head_strategy,\n",
    "        head_hidden=config.head_hidden,\n",
    "        head_dropout=config.head_dropout,\n",
    "    )\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "print(f\"\\nğŸ—ï¸  Model: Tier {TIER}\")\n",
    "print(f\"ğŸ“ˆ Total Parameters: {model.count_parameters():,}\")\n",
    "\n",
    "# Test forward pass\n",
    "sample_batch = next(iter(train_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    features = sample_batch['features'].to(DEVICE)\n",
    "    lengths = sample_batch['lengths']\n",
    "    \n",
    "    if TIER == 3:\n",
    "        q8_out, q3_out = model(features, lengths=lengths)\n",
    "    else:\n",
    "        q8_out, q3_out = model(features)\n",
    "\n",
    "print(f\"âœ“ Forward pass: {features.shape} â†’ Q8 {q8_out.shape}, Q3 {q3_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27686f14",
   "metadata": {},
   "source": [
    "## 7. Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde155a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_fn = get_multitask_loss(\n",
    "    loss_type=config.loss_type,\n",
    "    q8_weight=config.q8_loss_weight,\n",
    "    q3_weight=config.q3_loss_weight,\n",
    "    gamma=config.focal_gamma,\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = create_optimizer(\n",
    "    model,\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    optimizer_type='adamw',\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "scheduler = create_scheduler(\n",
    "    optimizer,\n",
    "    scheduler_type='cosine',\n",
    "    num_epochs=config.max_epochs,\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“‰ Loss: {config.loss_type}\")\n",
    "print(f\"âš¡ Optimizer: AdamW (lr={config.learning_rate})\")\n",
    "print(f\"ğŸ“… Scheduler: CosineAnnealing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7844c9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=DEVICE,\n",
    "    checkpoint_dir=config.checkpoint_dir,\n",
    "    gradient_clip=config.gradient_clip,\n",
    "    log_every=100,\n",
    "    use_amp=torch.cuda.is_available(),\n",
    "    use_tracking=False,  # Disabled for Kaggle\n",
    ")\n",
    "\n",
    "print(\"âœ“ Trainer initialized\")\n",
    "print(f\"   Checkpoint dir: {config.checkpoint_dir}\")\n",
    "print(f\"   Mixed Precision: {trainer.use_amp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf46b15",
   "metadata": {},
   "source": [
    "## 8. Train Model ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"â•\" * 60)\n",
    "print(\"ğŸš€ STARTING TRAINING\")\n",
    "print(\"â•\" * 60)\n",
    "\n",
    "history = trainer.train(\n",
    "    num_epochs=config.max_epochs,\n",
    "    patience=config.patience,\n",
    "    save_every=5,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"â•\" * 60)\n",
    "print(\"âœ… TRAINING COMPLETE\")\n",
    "print(\"â•\" * 60)\n",
    "print(f\"\\nğŸ“ˆ Best Results:\")\n",
    "print(f\"   Harmonic F1: {trainer.best_harmonic_f1:.4f}\")\n",
    "print(f\"   Q8 F1:       {trainer.best_q8_f1:.4f}\")\n",
    "print(f\"   Q8 Accuracy: {trainer.best_q8_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2386ebd1",
   "metadata": {},
   "source": [
    "## 9. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_SUBMISSION:\n",
    "    print(\"\\n\" + \"â•\" * 60)\n",
    "    print(\"ğŸ“ GENERATING SUBMISSION\")\n",
    "    print(\"â•\" * 60)\n",
    "    \n",
    "    # Load best model\n",
    "    best_checkpoint = torch.load(\n",
    "        Path(OUTPUT_DIR) / 'best_model.pt',\n",
    "        map_location=DEVICE\n",
    "    )\n",
    "    model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(f\"âœ“ Best model loaded (epoch {best_checkpoint.get('epoch', 'unknown')})\")\n",
    "    \n",
    "    # Load test data\n",
    "    test_dataset = HDF5EmbeddingDataset(\n",
    "        csv_path=TEST_CSV,\n",
    "        h5_path=EMBEDDINGS_PATH,\n",
    "        dataset_name='test',\n",
    "        max_length=config.max_seq_length,\n",
    "        is_test=True,\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=2,\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Test set loaded: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    all_ids = []\n",
    "    all_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            features = batch['features'].to(DEVICE)\n",
    "            lengths = batch['lengths']\n",
    "            ids = batch['ids']\n",
    "            \n",
    "            # Forward pass\n",
    "            if TIER == 3:\n",
    "                q8_logits, _ = model(features, lengths=lengths, return_q3=False)\n",
    "            else:\n",
    "                q8_logits, _ = model(features, return_q3=False)\n",
    "            \n",
    "            q8_preds = q8_logits.argmax(dim=-1)  # (batch, seq_len)\n",
    "            \n",
    "            # Convert to strings\n",
    "            for i, (sample_id, length) in enumerate(zip(ids, lengths)):\n",
    "                pred_indices = q8_preds[i, :length].cpu().numpy()\n",
    "                pred_str = ''.join([IDX_TO_SST8[idx] for idx in pred_indices])\n",
    "                all_ids.append(sample_id)\n",
    "                all_preds.append(pred_str)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': all_ids,\n",
    "        'sst8': all_preds,\n",
    "    })\n",
    "    \n",
    "    # Save submission\n",
    "    submission_path = Path(OUTPUT_DIR) / 'submission.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    \n",
    "    print(f\"\\nâœ… Submission saved: {submission_path}\")\n",
    "    print(f\"   Total predictions: {len(submission_df)}\")\n",
    "    print(f\"\\nğŸ“‹ Preview:\")\n",
    "    print(submission_df.head(10))\n",
    "    \n",
    "    # For Kaggle, also save to /kaggle/working for easy download\n",
    "    # submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "else:\n",
    "    print(\"â„¹ï¸  Submission generation disabled. Set GENERATE_SUBMISSION = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266f822",
   "metadata": {},
   "source": [
    "## 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"â•\" * 60)\n",
    "print(\"ğŸ‰ KAGGLE NOTEBOOK COMPLETE\")\n",
    "print(\"â•\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ—ï¸  Model Configuration:\")\n",
    "print(f\"   Tier: {TIER}\")\n",
    "print(f\"   PLM: {PLM_NAME}\")\n",
    "if TIER >= 2:\n",
    "    print(f\"   CNN: {CNN_TYPE}\")\n",
    "if TIER >= 3:\n",
    "    print(f\"   RNN: {RNN_TYPE}\")\n",
    "print(f\"   Loss: {LOSS_TYPE}\")\n",
    "print(f\"   Head: {HEAD_STRATEGY}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Training Results:\")\n",
    "print(f\"   Best Harmonic F1: {trainer.best_harmonic_f1:.4f}\")\n",
    "print(f\"   Best Q8 F1:       {trainer.best_q8_f1:.4f}\")\n",
    "print(f\"   Best Q8 Accuracy: {trainer.best_q8_accuracy:.4f}\")\n",
    "\n",
    "if GENERATE_SUBMISSION:\n",
    "    print(f\"\\nğŸ“ Submission:\")\n",
    "    print(f\"   File: {submission_path}\")\n",
    "    print(f\"   Predictions: {len(submission_df)}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Saved Files:\")\n",
    "print(f\"   {OUTPUT_DIR}/best_model.pt\")\n",
    "print(f\"   {OUTPUT_DIR}/submission.csv\")\n",
    "\n",
    "print(\"\\n\" + \"â•\" * 60)\n",
    "print(\"ğŸš€ Ready to submit to Kaggle!\")\n",
    "print(\"â•\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9154623",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Appendix: Extract Embeddings (Run Once)\n",
    "\n",
    "If you don't have pre-extracted embeddings, run this cell to extract them.\n",
    "**Save the output as a Kaggle Dataset for reuse!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# EMBEDDING EXTRACTION (Optional - Run once and save as dataset)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "EXTRACT_EMBEDDINGS = False  # Set to True to extract\n",
    "\n",
    "if EXTRACT_EMBEDDINGS:\n",
    "    import h5py\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    \n",
    "    # PLM to extract\n",
    "    EXTRACT_PLM = 'protbert'  # or 'esm2_8m', 'esm2_35m', 'esm2_650m'\n",
    "    \n",
    "    # PLM registry\n",
    "    PLM_REGISTRY = {\n",
    "        'protbert': ('Rostlab/prot_bert_bfd', 1024),\n",
    "        'esm2_8m': ('facebook/esm2_t6_8M_UR50D', 320),\n",
    "        'esm2_35m': ('facebook/esm2_t12_35M_UR50D', 480),\n",
    "        'esm2_650m': ('facebook/esm2_t33_650M_UR50D', 1280),\n",
    "    }\n",
    "    \n",
    "    model_name, emb_dim = PLM_REGISTRY[EXTRACT_PLM]\n",
    "    \n",
    "    print(f\"Loading {EXTRACT_PLM}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    plm_model = AutoModel.from_pretrained(model_name).eval()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        plm_model = plm_model.cuda()\n",
    "    \n",
    "    def extract_batch(sequences, batch_size=8):\n",
    "        embeddings = []\n",
    "        for i in tqdm(range(0, len(sequences), batch_size)):\n",
    "            batch_seqs = sequences[i:i+batch_size]\n",
    "            \n",
    "            # Tokenize (add spaces for ProtBert)\n",
    "            if 'protbert' in EXTRACT_PLM:\n",
    "                batch_seqs = [' '.join(list(seq)) for seq in batch_seqs]\n",
    "            \n",
    "            inputs = tokenizer(\n",
    "                batch_seqs,\n",
    "                return_tensors='pt',\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            )\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = plm_model(**inputs).last_hidden_state\n",
    "            \n",
    "            # Extract embeddings (remove special tokens)\n",
    "            for j, seq in enumerate(batch_seqs):\n",
    "                if 'protbert' in EXTRACT_PLM:\n",
    "                    seq_len = len(seq.split())\n",
    "                    emb = outputs[j, 1:seq_len+1, :].cpu().numpy()\n",
    "                else:\n",
    "                    seq_len = len(sequences[i+j])\n",
    "                    emb = outputs[j, 1:seq_len+1, :].cpu().numpy()\n",
    "                embeddings.append(emb)\n",
    "        \n",
    "        return embeddings\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    \n",
    "    print(f\"\\nExtracting train embeddings ({len(train_df)} samples)...\")\n",
    "    train_embs = extract_batch(train_df['sequence'].tolist())\n",
    "    \n",
    "    print(f\"\\nExtracting test embeddings ({len(test_df)} samples)...\")\n",
    "    test_embs = extract_batch(test_df['sequence'].tolist())\n",
    "    \n",
    "    # Save to HDF5\n",
    "    output_h5 = f'{OUTPUT_DIR}/{EXTRACT_PLM}.h5'\n",
    "    print(f\"\\nSaving to {output_h5}...\")\n",
    "    \n",
    "    with h5py.File(output_h5, 'w') as f:\n",
    "        f.attrs['plm_name'] = EXTRACT_PLM\n",
    "        f.attrs['embedding_dim'] = emb_dim\n",
    "        \n",
    "        train_grp = f.create_group('train')\n",
    "        for i, emb in enumerate(train_embs):\n",
    "            train_grp.create_dataset(str(train_df.iloc[i]['id']), data=emb)\n",
    "        \n",
    "        test_grp = f.create_group('test')\n",
    "        for i, emb in enumerate(test_embs):\n",
    "            test_grp.create_dataset(str(test_df.iloc[i]['id']), data=emb)\n",
    "    \n",
    "    print(f\"âœ… Embeddings saved to {output_h5}\")\n",
    "    print(f\"   Download this file and upload as a Kaggle Dataset!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
